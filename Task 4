# ğŸ“±âœ¨ Spam SMS Detector â€” Let's teach our model to say "Nope!" to shady messages!
# Imagine your phone has a smart assistant that reads every SMS and decides: "Is this spam or legit?" ğŸ•µï¸â€â™€ï¸ğŸ“©

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer  # ğŸ§  Turns words into math magic
from sklearn.naive_bayes import MultinomialNB                # ğŸ§  Our spam-spotting brain
from sklearn.metrics import classification_report, confusion_matrix  # ğŸ“Š Our model's report card

# 1ï¸âƒ£ Load the dataset
df = pd.read_csv("spam.csv", encoding="latin-1")  # Replace with your actual file name
df = df[["v1", "v2"]]  # Keep only label and message columns
df.columns = ["label", "message"]
print("ğŸ‘€ First peek at the data:\n", df.head())

# 2ï¸âƒ£ Convert labels to binary (ham = 0, spam = 1)
df["label"] = df["label"].map({"ham": 0, "spam": 1})
# ğŸ§¾ Think of 'ham' as friendly texts and 'spam' as sneaky ones

# 3ï¸âƒ£ Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    df["message"], df["label"], test_size=0.2, random_state=42
)
# ğŸ“ 80% for study time, 20% for exam time

# 4ï¸âƒ£ Convert text to TF-IDF features
# TF-IDF = Word highlighter pen âœï¸ğŸ“š (marks important words in each message)
vectorizer = TfidfVectorizer(stop_words="english")
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# 5ï¸âƒ£ Train the Naive Bayes model â€” our brain learns spam patterns ğŸ§ 
model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

# 6ï¸âƒ£ Time for the exam! Let's see how well it does ğŸ¯
y_pred = model.predict(X_test_tfidf)

# 7ï¸âƒ£ Print the results â€” like checking your grades ğŸ“‹
print("\nğŸ“Š Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nğŸ“‹ Classification Report:\n", classification_report(y_test, y_pred))
