# ğŸ“¦âœ¨ Customer Churn Prediction â€” Who's leaving the party?
# Imagine you're the host of a subscription service, and you want to know which guests might ghost you ğŸ˜¢

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler  # ğŸ§¼ Makes all features neat and fair
from sklearn.linear_model import LogisticRegression  # ğŸ§  Our churn-spotting brain
from sklearn.metrics import classification_report, confusion_matrix  # ğŸ“Š Our model's report card

# 1ï¸âƒ£ Load the dataset
df = pd.read_csv("customer_churn.csv")  # Replace with your actual file name
print("ğŸ‘€ First peek at the data:\n", df.head())

# 2ï¸âƒ£ Clean up the mess (no empty cells allowed!)
df.dropna(inplace=True)

# 3ï¸âƒ£ Split into features (X) and target (y)
X = df.drop("Churn", axis=1)  # All columns except 'Churn'
y = df["Churn"]               # 'Churn' is 1 if customer left, 0 if stayed

# 4ï¸âƒ£ Train-test split: study time vs exam time ğŸ“
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
# Stratify = make sure churners are evenly spread in both sets ğŸ°

# 5ï¸âƒ£ Scale the features (Logistic Regression likes clean numbers)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6ï¸âƒ£ Train the model â€” our brain learns patterns ğŸ§ 
model = LogisticRegression()
model.fit(X_train_scaled, y_train)

# 7ï¸âƒ£ Time for the exam! Let's see how well it does ğŸ¯
y_pred = model.predict(X_test_scaled)

# 8ï¸âƒ£ Print the results â€” like checking your grades ğŸ“‹
print("\nğŸ“Š Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nğŸ“‹ Classification Report:\n", classification_report(y_test, y_pred))
